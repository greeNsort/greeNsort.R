% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/greeNsort.R
\docType{data}
\name{KafkaParts}
\alias{KafkaParts}
\alias{KafkaWords}
\alias{KafkaWords_asc}
\alias{KafkaWords_desc}
\alias{KafkaWords_perm}
\alias{KafkaParts_asc}
\alias{KafkaParts_desc}
\alias{KafkaParts_perm}
\alias{BibleVerses}
\alias{BibleWords}
\alias{BibleWords_asc}
\alias{BibleWords_desc}
\alias{BibleWords_perm}
\alias{BibleVerses_asc}
\alias{BibleVerses_desc}
\alias{BibleVerses_perm}
\alias{GermanWords}
\alias{AustrianWords}
\alias{SwissWords}
\alias{VariantWords}
\alias{DictWords}
\alias{DictWords_asc}
\alias{DictWords_desc}
\alias{DictWords_perm}
\alias{DictWords_boot}
\alias{vtestdb}
\title{#' \Sexpr[echo=FALSE, results=rd, stage=build]{{thisalgo <- 'PVKnuth'; greeNsort::algodb[thisalgo,'name']}}
#'
#' \Sexpr[echo=FALSE, results=rd, stage=build]{gsub("(.*)(like )(.+)( but)(.*)","\\\\1like \\\\\\\\code{\\\\\\\\link{\\\\3} } but\\\\5",greeNsort::algodb[thisalgo,'desc'])}
#'
#' \Sexpr[echo=FALSE, results=text, stage=build]{greeNsort::algodb[thisalgo,'expl']}
#'
#' \Sexpr[echo=FALSE, results=verbatim, stage=build]{{i <- !colnames(greeNsort::algodb) \%in\% c('func','desc','expl'); cat(paste(colnames(greeNsort::algodb)[i], ' - ',  greeNsort::algodb[thisalgo,i], '\n', sep=''), sep='')}}
#'
#' See \code{\link{algodb}} for the complete table of algorithms.
#'
#' @param x a character vector to be sorted
#' @param situation "insitu" will only allocate buffer memory and use the existing RAM for sorting, "exsitu" will allocate completely fresh RAM for data and buffer
#' @param method an attempt to classify the implementation,  "index" means the implementation rather indexes into arrays, "pointer" rather uses pointer arithmetic
#' @param threads the number of threads to use, default \code{\link{perfcores}}
#' @return like \code{\link{rawperf}}
#' @seealso
#' \code{\link{UZacksort}} for indirect Zacksort using pointers to size-varying elements (strings, not stable),
#' \code{\link{WQuicksort2}} for indirect stabilized quicksort using pointers  to size-varying elements (strings, no ties by definition),
#' \code{\link{VKnuthsort}} for direct mergesort of size-varying elements (strings) using Knuth's merge with one loop check,
#' \code{\link{VFrogsort1}} for direct frogsort of size-varying elements (strings),
#' \code{\link{VKnuthsortA}} for an adaptive tuned version,
#' \code{\link{Knuthsort}} for the version for equally-sized elements,
#' @examples
#' x <- vtestdb$func$KafkaWords()
#' rbind(
#'  {y <- x[]; sperf(UZacksort(y))}
#' ,{y <- x[]; sperf(WQuicksort2(y))}
#' ,{y <- x[]; sperf(VKnuthsort(y))}
#' ,{y <- x[]; sperf(VFrogsort1(y))}
#' ,{y <- x[]; sperf(UZacksortB(y))}
#' ,{y <- x[]; sperf(WQuicksort2B(y))}
#' ,{y <- x[]; sperf(VKnuthsortA(y))}
#' ,{y <- x[]; sperf(VFrogsort1A(y))}
#' )
#' @export}
\format{
A data frame with one row per test generator and these columns:
\describe{
  \item{ name }{ full test name }
  \item{ label }{ abbreviated test label}
  \item{ desc }{ a description of the test }
  \item{ major }{ one letter classifiying the test as 'P'=Permutation, 'A' = Ascending, 'D' = Descending' 'a' = AscendingDescending, 'd'= DescendingAscending, 'T'= Ties, 'B' = Ascending with ties, 'S' = Stability }
  \item{ minor }{ one letter identifying the test }
  \item{ stable }{ \code{TRUE} if the data is suitable for stability testing via \code{\link{current_keys}}, \code{FALSE} otherwise }
  \item{ entropy }{ entropy }
  \item{ relentropy }{ relative entropy }
  \item{ monotAscFrac }{ fraction of ascending differences }
  \item{ spearman }{ Spearman correation between position and value }
  \item{ strictAscFrac }{  fraction of strictly ascending differences }
  \item{ code }{ the test generator code }
  \item{ func }{ the callable test generator function }
  }
}
\usage{
KafkaParts()

KafkaWords()

KafkaWords_asc()

KafkaWords_desc()

KafkaWords_perm()

KafkaParts_asc()

KafkaParts_desc()

KafkaParts_perm()

BibleVerses()

BibleWords()

BibleWords_asc()

BibleWords_desc()

BibleWords_perm()

BibleVerses_asc()

BibleVerses_desc()

BibleVerses_perm()

GermanWords()

AustrianWords()

SwissWords()

VariantWords()

DictWords()

DictWords_asc()

DictWords_desc()

DictWords_perm()

DictWords_boot()

vtestdb
}
\description{
PVKnuthsort <- function(x
                        , situation=c("insitu","exsitu")
                        , method=c("index")
                        , threads = perfcores()
)
{
  stop("not yet implemented in parallel")
  if (!is.character(x))
    stop("only character vectors implemented")
  situation <- match.arg(situation)
  method <- match.arg(method)
  if (situation == 'insitu') {
    ret <- .Call(C_r_PVKnuthsort_insitu
                 , x = x
                 , t = as.double(threads)
    )
  }else{
    ret <- .Call(C_r_PVKnuthsort_exsitu
                 , x = x
                 , t = as.double(threads)
    )
  }
  ret <- retperf(ret, "PVKnuthsort")
  ret
}

A dataset describing all testdata generators in this package.
}
\details{
#' \Sexpr[echo=FALSE, results=rd, stage=build]{{thisalgo <- '?PVFrog1'; greeNsort::algodb[thisalgo,'name']}}
#'
#' \Sexpr[echo=FALSE, results=rd, stage=build]{gsub("(.*)(like )(.+)( but)(.*)","\\\\1like \\\\\\\\code{\\\\\\\\link{\\\\3} } but\\\\5",greeNsort::algodb[thisalgo,'desc'])}
#'
#' \Sexpr[echo=FALSE, results=text, stage=build]{greeNsort::algodb[thisalgo,'expl']}
#'
#' \Sexpr[echo=FALSE, results=verbatim, stage=build]{{i <- !colnames(greeNsort::algodb) \%in\% c('func','desc','expl'); cat(paste(colnames(greeNsort::algodb)[i], ' - ',  greeNsort::algodb[thisalgo,i], '\n', sep=''), sep='')}}
#'
#' See \code{\link{algodb}} for the complete table of algorithms.
#'
#' @param x a character vector to be sorted
#' @param situation "insitu" will only allocate buffer memory and use the existing RAM for sorting, "exsitu" will allocate completely fresh RAM for data and buffer
#' @param method an attempt to classify the implementation,  "index" means the implementation rather indexes into arrays, "pointer" rather uses pointer arithmetic
#' @param threads the number of threads to use, default \code{\link{perfcores}}
#' @return like \code{\link{rawperf}}
#' @seealso
#' \code{\link{UZacksort}} for indirect Zacksort using pointers to size-varying elements (strings, not stable),
#' \code{\link{WQuicksort2}} for indirect stabilized quicksort using pointers  to size-varying elements (strings, no ties by definition),
#' \code{\link{VKnuthsort}} for direct mergesort of size-varying elements (strings) using Knuth's merge with one loop check,
#' \code{\link{VFrogsort1}} for direct frogsort of size-varying elements (strings),
#' \code{\link{VFrogsort1A}} for an adaptive tuned version,
#' \code{\link{Frogsort1}} for the version for equally-sized elements,
#' @examples
#' x <- vtestdb$func$KafkaWords()
#' rbind(
#'  {y <- x[]; sperf(UZacksort(y))}
#' ,{y <- x[]; sperf(WQuicksort2(y))}
#' ,{y <- x[]; sperf(VKnuthsort(y))}
#' ,{y <- x[]; sperf(VFrogsort1(y))}
#' ,{y <- x[]; sperf(UZacksortB(y))}
#' ,{y <- x[]; sperf(WQuicksort2B(y))}
#' ,{y <- x[]; sperf(VKnuthsortA(y))}
#' ,{y <- x[]; sperf(VFrogsort1A(y))}
#' )
#' @export

PVFrogsort1 <- function(x
                        , situation=c("insitu","exsitu")
                        , method=c("index")
                        , threads = perfcores()
)
{
  stop("not yet implemented in parallel")
  if (!is.character(x))
    stop("only character vectors implemented")
  situation <- match.arg(situation)
  method <- match.arg(method)
  if (situation == "insitu")
    ret <- .Call(C_r_PVFrogsort1_insitu
                 , x = x
                 , t = as.double(threads)
    )
  else
    ret <- .Call(C_r_PVFrogsort1_exsitu
                 , x = x
                 , t = as.double(threads)
    )
  ret <- retperf(ret, "PVFrogsort1")
  ret
}
}
\section{Functions}{
\itemize{
\item \code{KafkaParts()}: Kafka Paragraphs in natural sequence

\item \code{KafkaWords()}: Kafka Words in natural sequence

\item \code{KafkaWords_asc()}: Kafka Words sorted ascending

\item \code{KafkaWords_desc()}: Kafka Words sorted descending

\item \code{KafkaWords_perm()}: Kafka Words randomly permuted

\item \code{KafkaParts_asc()}: Kafka Parts sorted ascending

\item \code{KafkaParts_desc()}: Kafka Parts sorted descending

\item \code{KafkaParts_perm()}: Kafka Parts randomly permuted

\item \code{BibleVerses()}: Bible Verse tokens in natural sequence

\item \code{BibleWords()}: Bible Word tokens in natural sequence

\item \code{BibleWords_asc()}: Bible Words sorted ascending

\item \code{BibleWords_desc()}: Bible Words sorted descending

\item \code{BibleWords_perm()}: Bible Words randomly permuted

\item \code{BibleVerses_asc()}: Bible Verses sorted ascending

\item \code{BibleVerses_desc()}: Bible Verses sorted descending

\item \code{BibleVerses_perm()}: Bible Verses randomly permuted

\item \code{GermanWords()}: dictionary of german Words sorted

\item \code{AustrianWords()}: dictionary of austrian Words sorted

\item \code{SwissWords()}: dictionary of swiss Words sorted

\item \code{VariantWords()}: dictionary of variant Words sorted

\item \code{DictWords()}: dictionary of German languages, concatenation of  4 subdictionaries (German, Austrian, Swiss, Variant), hence partially sorted

\item \code{DictWords_asc()}: dictionary ascending

\item \code{DictWords_desc()}: dictionary descending

\item \code{DictWords_perm()}: dictionary randomly permuted

\item \code{DictWords_boot()}: dictionary bootstrap sample (63% distinct, 37% duplicates)

}}
\examples{
  table(vtestdb$major)
  table(vtestdb$minor)
  summary(vtestdb$entropy)
  summary(vtestdb$relentropy)
  summary(vtestdb$monotAscFrac)
  summary(vtestdb$strictAscFrac)
  summary(vtestdb$spearman)
  \donttest{
    View(vtestdb)
  }

}
\seealso{
\code{\link{vtestdb}} and \code{\link{algodb}}
}
\keyword{datasets}
